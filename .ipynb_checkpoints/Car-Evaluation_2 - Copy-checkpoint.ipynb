{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "04b8dc55-935f-4dbe-a978-e7505c5d3407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd31d67-9fdc-4f9d-b113-d2091cf41500",
   "metadata": {},
   "source": [
    "__Importing the Car Evaluation Dataset__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63cdbea0-3c0f-43c0-9476-e78c31ff52a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "car_evaluation = fetch_ucirepo(id=19) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = car_evaluation.data.features \n",
    "y = car_evaluation.data.targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6270681a-0067-4fc4-b1fe-527dc65ef018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(1728, 6)\n",
      "(1728, 1)\n"
     ]
    }
   ],
   "source": [
    "print(type(X))\n",
    "print(type(y))\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccb4b1f-9e7b-4444-baaa-7f9e170833bd",
   "metadata": {},
   "source": [
    "__One Hot Encoding__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "986e15d7-57c7-4db0-b08d-374c89539dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(1728, 21)\n",
      "(1728, 4)\n"
     ]
    }
   ],
   "source": [
    "X_encoded = pd.get_dummies(X) # One hot encoding\n",
    "y_encoded = pd.get_dummies(y) # One hot encoding\n",
    "\n",
    "# print(X_encoded)\n",
    "# print(y_encoded)\n",
    "\n",
    "print(type(X))\n",
    "print(type(y))\n",
    "\n",
    "print(X_encoded.shape)\n",
    "print(y_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098c3739-2b76-49a8-855d-dd581d7e92ca",
   "metadata": {},
   "source": [
    "__Dataset Partitioning__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "30a0b76c-11c1-42ec-b3e4-52452cc2a71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# data split, 70% training and 30% temp (temp = validation + test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_encoded, y_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    "# 30% temp data into 15% validation and 15% test\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ca26ff-3bb0-4065-8034-8ae886e8ed93",
   "metadata": {},
   "source": [
    "__Building a Single Decision Tree__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "42c933ef-8bf6-409b-b408-0282138bb29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "single_decision_tree_classifier = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "33f59881-5604-4c5a-bd8a-fe178134d182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_decision_tree_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "92d97061-40ee-4faf-ad8c-0dd1e83eab30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import plot_tree\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(40, 20))\n",
    "# plot_tree(single_decision_tree_classifier, filled=True, feature_names=X_train.columns, class_names=single_decision_tree_classifier.classes_)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "535c1f37-d56b-4dc4-b02f-0cc5baa5c04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 11, 'min_samples_leaf': 1, 'min_samples_split': 2, 'random_state': 42}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "dt_params = {'max_depth': [3,4,5,6,7,8,9,10,11], 'min_samples_split': [2,3,4,5,6,7,8,9,10,11],'min_samples_leaf':[1,2,3,4,5],'random_state':[42]}\n",
    "dt_grid = GridSearchCV(DecisionTreeClassifier(), dt_params, cv=5, scoring='accuracy')\n",
    "dt_grid.fit(X_train, y_train)\n",
    "best_params = dt_grid.best_params_\n",
    "print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4a4b5c-7139-49c7-94a3-6743fc3f5adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = DecisionTreeClassifier(max_depth=10, min_samples_split=4,criterion='gini',    min_samples_leaf=1,  random_state=42)\n",
    "model2 = DecisionTreeClassifier(max_depth=9,  min_samples_split=5,criterion='entropy', min_samples_leaf=4,  random_state=42)\n",
    "model3 = DecisionTreeClassifier(max_depth=5,  min_samples_split=2,criterion='gini',    min_samples_leaf=10, random_state=42)\n",
    "model4 = DecisionTreeClassifier(max_depth=3,  min_samples_split=3,criterion='entropy', min_samples_leaf=7,  random_state=42)\n",
    "\n",
    "\n",
    "model1.fit(X_train, y_train)\n",
    "model2.fit(X_train, y_train)\n",
    "model3.fit(X_train, y_train)\n",
    "model4.fit(X_train, y_train)\n",
    "\n",
    "y_pred_val1 = model1.predict(X_val)\n",
    "y_pred_val2 = model2.predict(X_val)\n",
    "y_pred_val3 = model3.predict(X_val)\n",
    "y_pred_val4 = model4.predict(X_val)\n",
    "\n",
    "val_accuracy = accuracy_score(y_val, y_pred_val1)\n",
    "val_precision, val_recall, val_f1, val_support = precision_recall_fscore_support(y_val, y_pred_val1, average=None)\n",
    "print(\"1\")\n",
    "print(\"Accuracy:\", val_accuracy)\n",
    "print(\"Precision:\", val_precision)\n",
    "print(\"Recall:\", val_recall)\n",
    "print(\"F1-score:\", val_f1)\n",
    "\n",
    "val_accuracy = accuracy_score(y_val, y_pred_val2)\n",
    "val_precision, val_recall, val_f1, val_support = precision_recall_fscore_support(y_val, y_pred_val2, average=None)\n",
    "print(\"2\")\n",
    "print(\"Accuracy:\", val_accuracy)\n",
    "print(\"Precision:\", val_precision)\n",
    "print(\"Recall:\", val_recall)\n",
    "print(\"F1-score:\", val_f1)\n",
    "\n",
    "val_accuracy = accuracy_score(y_val, y_pred_val3)\n",
    "val_precision, val_recall, val_f1, val_support = precision_recall_fscore_support(y_val, y_pred_val3, average=None)\n",
    "print(\"3\")\n",
    "print(\"Accuracy:\", val_accuracy)\n",
    "print(\"Precision:\", val_precision)\n",
    "print(\"Recall:\", val_recall)\n",
    "print(\"F1-score:\", val_f1)\n",
    "\n",
    "val_accuracy = accuracy_score(y_val, y_pred_val4)\n",
    "val_precision, val_recall, val_f1, val_support = precision_recall_fscore_support(y_val, y_pred_val4, average=None)\n",
    "print(\"4\")\n",
    "print(\"Accuracy:\", val_accuracy)\n",
    "print(\"Precision:\", val_precision)\n",
    "print(\"Recall:\", val_recall)\n",
    "print(\"F1-score:\", val_f1)\n",
    "\n",
    "y_pred_test = model3.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "test_precision, test_recall, test_f1, test_support = precision_recall_fscore_support(y_test, y_pred_test, average=None)\n",
    "print(\"_TEST SET RESULTS_\")\n",
    "print(\"Accuracy:\", test_accuracy)\n",
    "print(\"Precision:\", test_precision)\n",
    "print(\"Recall:\", test_recall)\n",
    "print(\"F1-score:\", test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "38f09a44-7017-4aba-a862-00f286ac4916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # Hyperparameter Tuning for Decision Tree Classifier\n",
    "# dt_params = {'max_depth': [10, 11, 12, 13, 14, 15, 16], 'min_samples_split': [2, 3, 4, 5, 5, 6, 7, 8, 9]}\n",
    "# dt_grid = GridSearchCV(DecisionTreeClassifier(), dt_params, cv=5, scoring='accuracy')\n",
    "# dt_grid.fit(X_train, y_train)\n",
    "\n",
    "# best_params = dt_grid.best_params_\n",
    "# print(f\"Best Hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2c9718f7-4a18-4070-a90a-3c47077c2fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Retrieve the best parameters from GridSearchCV\n",
    "# # best_params = dt_grid.best_params_\n",
    "\n",
    "# # Step 2: Initialize a new Decision Tree Classifier with the best parameters\n",
    "# best_dt_model = DecisionTreeClassifier(**best_params)\n",
    "\n",
    "# # Step 3: Fit the model on the training set\n",
    "# best_dt_model.fit(X_train, y_train)\n",
    "\n",
    "# # Step 4: Evaluate on the validation set\n",
    "# y_val_pred = best_dt_model.predict(X_val)\n",
    "# val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "# print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "# # Step 5: Evaluate on the test set\n",
    "# y_test_pred = best_dt_model.predict(X_test)\n",
    "# test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "# print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad93a20-8393-4cbd-b685-c88c768a7ea5",
   "metadata": {},
   "source": [
    "__Validation Set__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "96147f39-d7eb-4763-af53-de2c92563f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      class_acc  class_good  class_unacc  class_vgood\n",
      "192       False       False         True        False\n",
      "834       False       False         True        False\n",
      "677       False       False         True        False\n",
      "1516      False       False         True        False\n",
      "1157      False       False        False         True\n",
      "...         ...         ...          ...          ...\n",
      "582       False       False         True        False\n",
      "1450       True       False        False        False\n",
      "244       False       False         True        False\n",
      "907        True       False        False        False\n",
      "1540      False       False         True        False\n",
      "\n",
      "[259 rows x 4 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(259, 4)\n",
      "[[False False  True False]\n",
      " [False False  True False]\n",
      " [False False  True False]\n",
      " ...\n",
      " [False False  True False]\n",
      " [ True False False False]\n",
      " [False False  True False]]\n",
      "<class 'numpy.ndarray'>\n",
      "(259, 4)\n"
     ]
    }
   ],
   "source": [
    "# y_val contains actual ground truth labels of the validation set\n",
    "# y_val_pred is our model's prediction on the X_val (validation set)\n",
    "\n",
    "y_val_pred = single_decision_tree_classifier.predict(X_val)\n",
    "\n",
    "print(y_val)\n",
    "print(type(y_val))\n",
    "print(y_val.shape)\n",
    "\n",
    "print(y_val_pred)\n",
    "print(type(y_val_pred))\n",
    "print(y_val_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "36b61f94-0774-49a2-ae7b-76c3fde70637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259\n",
      "4\n",
      "259\n",
      "4\n",
      "rows = 259\n",
      "columns = 4\n"
     ]
    }
   ],
   "source": [
    "y_val_rows, y_val_cols = y_val.shape\n",
    "print(y_val_rows)\n",
    "print(y_val_cols)\n",
    "\n",
    "y_val_pred_rows, y_val_pred_cols = y_val_pred.shape\n",
    "print(y_val_pred_rows)\n",
    "print(y_val_pred_cols)\n",
    "\n",
    "if y_val_rows == y_val_pred_rows:\n",
    "    rows = y_val_rows\n",
    "    print(f\"rows = {rows}\")\n",
    "\n",
    "if y_val_cols == y_val_pred_cols:\n",
    "    cols = y_val_cols\n",
    "    print(f\"columns = {cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3b9f09-5589-4cc5-961a-1f7b6a7efe11",
   "metadata": {},
   "source": [
    "__Manually building the Confusion Matrix on the Validation Set__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "919103a4-a4cf-4084-9128-407b0e1e8248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[51, 2, 2, 2]\n",
      "[0, 9, 0, 1]\n",
      "[1, 0, 177, 0]\n",
      "[1, 1, 0, 12]\n"
     ]
    }
   ],
   "source": [
    "acc_acc = acc_good = acc_unacc = acc_vgood = 0\n",
    "good_acc = good_good = good_unacc = good_vgood = 0\n",
    "unacc_acc = unacc_good = unacc_unacc = unacc_vgood = 0\n",
    "vgood_acc = vgood_good = vgood_unacc = vgood_vgood = 0\n",
    "\n",
    "for i in range(rows):\n",
    "    actual = y_val.iloc[i].values # <class 'pandas.core.frame.DataFrame'>\n",
    "    predicted = y_val_pred[i] # <class 'numpy.ndarray'>\n",
    "    \n",
    "    if actual[0] == True and predicted[0] == True:\n",
    "        acc_acc += 1\n",
    "    elif actual[0] == True and predicted[1] == True:\n",
    "        acc_good += 1\n",
    "    elif actual[0] == True and predicted[2] == True:\n",
    "        acc_unacc += 1\n",
    "    elif actual[0] == True and predicted[3] == True:\n",
    "        acc_vgood += 1\n",
    "    \n",
    "    if actual[1] == True and predicted[0] == True:\n",
    "        good_acc += 1\n",
    "    elif actual[1] == True and predicted[1] == True:\n",
    "        good_good += 1\n",
    "    elif actual[1] == True and predicted[2] == True:\n",
    "        good_unacc += 1\n",
    "    elif actual[1] == True and predicted[3] == True:\n",
    "        good_vgood += 1\n",
    "\n",
    "    if actual[2] == True and predicted[0] == True:\n",
    "        unacc_acc += 1\n",
    "    elif actual[2] == True and predicted[1] == True:\n",
    "        unacc_good += 1\n",
    "    elif actual[2] == True and predicted[2] == True:\n",
    "        unacc_unacc += 1\n",
    "    elif actual[2] == True and predicted[3] == True:\n",
    "        unacc_vgood += 1\n",
    "\n",
    "    if actual[3] == True and predicted[0] == True:\n",
    "        vgood_acc += 1\n",
    "    elif actual[3] == True and predicted[1] == True:\n",
    "        vgood_good += 1\n",
    "    elif actual[3] == True and predicted[2] == True:\n",
    "        vgood_unacc += 1\n",
    "    elif actual[3] == True and predicted[3] == True:\n",
    "        vgood_vgood += 1\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(f\"[{acc_acc}, {acc_good}, {acc_unacc}, {acc_vgood}]\")\n",
    "print(f\"[{good_acc}, {good_good}, {good_unacc}, {good_vgood}]\")\n",
    "print(f\"[{unacc_acc}, {unacc_good}, {unacc_unacc}, {unacc_vgood}]\")\n",
    "print(f\"[{vgood_acc}, {vgood_good}, {vgood_unacc}, {vgood_vgood}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bff66b8-ad22-4fe1-a3ba-de9c93968135",
   "metadata": {},
   "source": [
    "__Creating a List Containing the Confusion Matrix of Validation Set__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "38235966-9cf5-4997-8de7-fdb4c3119137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[51, 2, 2, 2], [0, 9, 0, 1], [1, 0, 177, 0], [1, 1, 0, 12]]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = [[acc_acc, acc_good, acc_unacc, acc_vgood],\n",
    "                   [good_acc, good_good, good_unacc, good_vgood],\n",
    "                   [unacc_acc, unacc_good, unacc_unacc, unacc_vgood],\n",
    "                   [vgood_acc, vgood_good, vgood_unacc, vgood_vgood]]\n",
    "print(confusion_matrix)\n",
    "print(type(confusion_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c062d699-c37e-481b-88c5-0ffb3c0c6c1b",
   "metadata": {},
   "source": [
    "__Manually Calculating the Validation Set's Accuracy from the Manually Built Confusion Matrix__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1ee731d5-39e9-4dda-8184-571fe78f3f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9613899613899614\n"
     ]
    }
   ],
   "source": [
    "print((acc_acc + good_good + unacc_unacc + vgood_vgood) / sum(sum(row) for row in confusion_matrix))\n",
    "\n",
    "# print((acc_acc + good_good + unacc_unacc + vgood_vgood) / (acc_acc + acc_good + acc_unacc + acc_vgood + good_acc + good_good + good_unacc + good_vgood + unacc_acc + unacc_good + unacc_unacc + unacc_vgood + vgood_acc + vgood_good + vgood_unacc + vgood_vgood))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5097a488-5299-4572-a293-0a6832520465",
   "metadata": {},
   "source": [
    "__Accuracy of the Single Decision Tree on the Validation Set__ `using the Sklearn Implementation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "53977d44-243d-4971-9320-b955e607a6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9613899613899614\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# y_val_pred = single_decision_tree_classifier.predict(X_val)\n",
    "\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644e32d9-9936-4933-923d-80f831a4e54a",
   "metadata": {},
   "source": [
    "__Manually Calculating the Validation Set's Precision & Recall from the Manually Built Confusion Matrix__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6a9047a8-7d37-4fb6-9798-cd8a0f174d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of acc: 0.9622641509433962\n",
      "Precision of good: 0.75\n",
      "Precision of unacc: 0.9888268156424581\n",
      "Precision of vgood: 0.8\n",
      "---------------------------------------\n",
      "Average Precision: 0.8752727416464636\n",
      "---------------------------------------\n",
      "Recall of acc: 0.8947368421052632\n",
      "Recall of good: 0.9\n",
      "Recall of unacc: 0.9943820224719101\n",
      "Recall of vgood: 0.8571428571428571\n",
      "---------------------------------------\n",
      "Average recall: 0.9115654304300076\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Average F1 Score: 0.8930505134165727\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Precision of acc\n",
    "# print(acc_acc / (acc_acc + good_acc + unacc_acc + vgood_acc))\n",
    "Precision_of_acc = acc_acc / (acc_acc + good_acc + unacc_acc + vgood_acc)\n",
    "print(f\"Precision of acc: {Precision_of_acc}\")\n",
    "\n",
    "# Precision of good\n",
    "# print(good_good / (acc_good + good_good + unacc_good + vgood_good))\n",
    "Precision_of_good = good_good / (acc_good + good_good + unacc_good + vgood_good)\n",
    "print(f\"Precision of good: {Precision_of_good}\")\n",
    "\n",
    "# Precision of unacc\n",
    "# print(unacc_unacc / (acc_unacc + good_unacc + unacc_unacc + vgood_unacc))\n",
    "Precision_of_unacc = unacc_unacc / (acc_unacc + good_unacc + unacc_unacc + vgood_unacc)\n",
    "print(f\"Precision of unacc: {Precision_of_unacc}\")\n",
    "\n",
    "# Precision of vgood\n",
    "# print(vgood_vgood / (acc_vgood + good_vgood + unacc_vgood + vgood_vgood))\n",
    "Precision_of_vgood = vgood_vgood / (acc_vgood + good_vgood + unacc_vgood + vgood_vgood)\n",
    "print(f\"Precision of vgood: {Precision_of_vgood}\")\n",
    "\n",
    "# Average precision\n",
    "average_precision = (Precision_of_acc + Precision_of_good + Precision_of_unacc + Precision_of_vgood) / 4.0\n",
    "print(\"---------------------------------------\")\n",
    "print(f\"Average Precision: {average_precision}\")\n",
    "print(\"---------------------------------------\")\n",
    "\n",
    "# Recall of acc\n",
    "Recall_of_acc = acc_acc / (acc_acc + acc_good + acc_unacc + acc_vgood)\n",
    "print(f\"Recall of acc: {Recall_of_acc}\")\n",
    "\n",
    "# Recall of good\n",
    "Recall_of_good = good_good / (good_acc + good_good + good_unacc + good_vgood)\n",
    "print(f\"Recall of good: {Recall_of_good}\")\n",
    "\n",
    "# Recall of unacc\n",
    "Recall_of_unacc = unacc_unacc / (unacc_acc + unacc_good + unacc_unacc + unacc_vgood)\n",
    "print(f\"Recall of unacc: {Recall_of_unacc}\")\n",
    "\n",
    "# Recall of vgood\n",
    "Recall_of_vgood = vgood_vgood / (vgood_acc + vgood_good + vgood_unacc + vgood_vgood)\n",
    "print(f\"Recall of vgood: {Recall_of_vgood}\")\n",
    "\n",
    "# Average recall\n",
    "average_recall = (Recall_of_acc + Recall_of_good + Recall_of_unacc + Recall_of_vgood) / 4.0\n",
    "print(\"---------------------------------------\")\n",
    "print(f\"Average recall: {average_recall}\")\n",
    "print(\"---------------------------------------\")\n",
    "\n",
    "# Average F1 Score\n",
    "average_f1_score = 2 * ((average_precision * average_recall) / (average_precision + average_recall))\n",
    "print(\"---------------------------------------\")\n",
    "print(f\"Average F1 Score: {average_f1_score}\")\n",
    "print(\"---------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3582357e-ad6c-4a7b-83a1-63c026fd94a3",
   "metadata": {},
   "source": [
    "__Confusion Matrix, Precision, Recall, F1 Score on the Validation Set__ `using the Sklearn Implementation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "27a895eb-6650-41f1-9665-d811d989d6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix using sklearn:\n",
      "[[ 51   2   2   2]\n",
      " [  0   9   0   1]\n",
      " [  1   0 177   0]\n",
      " [  1   1   0  12]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.93        57\n",
      "           1       0.75      0.90      0.82        10\n",
      "           2       0.99      0.99      0.99       178\n",
      "           3       0.80      0.86      0.83        14\n",
      "\n",
      "    accuracy                           0.96       259\n",
      "   macro avg       0.88      0.91      0.89       259\n",
      "weighted avg       0.96      0.96      0.96       259\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "y_val_labels = np.argmax(y_val.values, axis=1)\n",
    "y_val_pred_labels = np.argmax(y_val_pred, axis=1)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_val_labels, y_val_pred_labels)\n",
    "\n",
    "print(\"Confusion Matrix using sklearn:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val_labels, y_val_pred_labels, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3f9e14-77fb-4f48-a473-3dd29832fc8c",
   "metadata": {},
   "source": [
    "__Test Set__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3a8d4b75-34e0-4dc7-993c-79d1daaf0547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      class_acc  class_good  class_unacc  class_vgood\n",
      "974       False       False         True        False\n",
      "78        False       False         True        False\n",
      "23        False       False         True        False\n",
      "813       False       False         True        False\n",
      "1356      False       False         True        False\n",
      "...         ...         ...          ...          ...\n",
      "998        True       False        False        False\n",
      "1221      False       False         True        False\n",
      "367        True       False        False        False\n",
      "1428      False       False         True        False\n",
      "1118       True       False        False        False\n",
      "\n",
      "[260 rows x 4 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(260, 4)\n",
      "[[False False  True False]\n",
      " [False False  True False]\n",
      " [False False  True False]\n",
      " ...\n",
      " [ True False False False]\n",
      " [False False  True False]\n",
      " [ True False False False]]\n",
      "<class 'numpy.ndarray'>\n",
      "(260, 4)\n"
     ]
    }
   ],
   "source": [
    "# y_test contains actual ground truth labels of the test set\n",
    "# y_test_pred is our model's prediction on the X_test (Test set)\n",
    "\n",
    "y_test_pred = single_decision_tree_classifier.predict(X_test)\n",
    "\n",
    "print(y_test)\n",
    "print(type(y_test))\n",
    "print(y_test.shape)\n",
    "\n",
    "print(y_test_pred)\n",
    "print(type(y_test_pred))\n",
    "print(y_test_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "42ba6c8a-c87b-4170-bd7a-6362e9f581ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260\n",
      "4\n",
      "260\n",
      "4\n",
      "rows = 260\n",
      "columns = 4\n"
     ]
    }
   ],
   "source": [
    "y_test_rows, y_test_cols = y_test.shape\n",
    "print(y_test_rows)\n",
    "print(y_test_cols)\n",
    "\n",
    "y_test_pred_rows, y_test_pred_cols = y_test_pred.shape\n",
    "print(y_test_pred_rows)\n",
    "print(y_test_pred_cols)\n",
    "\n",
    "if y_test_rows == y_test_pred_rows:\n",
    "    rows = y_test_rows\n",
    "    print(f\"rows = {rows}\")\n",
    "\n",
    "if y_test_cols == y_test_pred_cols:\n",
    "    cols = y_test_cols\n",
    "    print(f\"columns = {cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0fa8a9-14ca-4d53-9316-c1a18866f887",
   "metadata": {},
   "source": [
    "__Manually building the Confusion Matrix on the Test Set__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3d0e47d4-8328-45f2-bb52-ca8529e0ec97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[53, 2, 5, 1]\n",
      "[0, 9, 0, 0]\n",
      "[2, 0, 178, 0]\n",
      "[2, 1, 0, 7]\n"
     ]
    }
   ],
   "source": [
    "acc_acc = acc_good = acc_unacc = acc_vgood = 0\n",
    "good_acc = good_good = good_unacc = good_vgood = 0\n",
    "unacc_acc = unacc_good = unacc_unacc = unacc_vgood = 0\n",
    "vgood_acc = vgood_good = vgood_unacc = vgood_vgood = 0\n",
    "\n",
    "for i in range(rows):\n",
    "    actual = y_test.iloc[i].values # <class 'pandas.core.frame.DataFrame'>\n",
    "    predicted = y_test_pred[i] # <class 'numpy.ndarray'>\n",
    "    \n",
    "    if actual[0] == True and predicted[0] == True:\n",
    "        acc_acc += 1\n",
    "    elif actual[0] == True and predicted[1] == True:\n",
    "        acc_good += 1\n",
    "    elif actual[0] == True and predicted[2] == True:\n",
    "        acc_unacc += 1\n",
    "    elif actual[0] == True and predicted[3] == True:\n",
    "        acc_vgood += 1\n",
    "    \n",
    "    if actual[1] == True and predicted[0] == True:\n",
    "        good_acc += 1\n",
    "    elif actual[1] == True and predicted[1] == True:\n",
    "        good_good += 1\n",
    "    elif actual[1] == True and predicted[2] == True:\n",
    "        good_unacc += 1\n",
    "    elif actual[1] == True and predicted[3] == True:\n",
    "        good_vgood += 1\n",
    "\n",
    "    if actual[2] == True and predicted[0] == True:\n",
    "        unacc_acc += 1\n",
    "    elif actual[2] == True and predicted[1] == True:\n",
    "        unacc_good += 1\n",
    "    elif actual[2] == True and predicted[2] == True:\n",
    "        unacc_unacc += 1\n",
    "    elif actual[2] == True and predicted[3] == True:\n",
    "        unacc_vgood += 1\n",
    "\n",
    "    if actual[3] == True and predicted[0] == True:\n",
    "        vgood_acc += 1\n",
    "    elif actual[3] == True and predicted[1] == True:\n",
    "        vgood_good += 1\n",
    "    elif actual[3] == True and predicted[2] == True:\n",
    "        vgood_unacc += 1\n",
    "    elif actual[3] == True and predicted[3] == True:\n",
    "        vgood_vgood += 1\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(f\"[{acc_acc}, {acc_good}, {acc_unacc}, {acc_vgood}]\")\n",
    "print(f\"[{good_acc}, {good_good}, {good_unacc}, {good_vgood}]\")\n",
    "print(f\"[{unacc_acc}, {unacc_good}, {unacc_unacc}, {unacc_vgood}]\")\n",
    "print(f\"[{vgood_acc}, {vgood_good}, {vgood_unacc}, {vgood_vgood}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f565b87-83c2-4cac-987e-123d743874fa",
   "metadata": {},
   "source": [
    "__Creating a List Containing the Confusion Matrix of Test Set__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0f035141-ef08-492c-95cb-485a323f0296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[53, 2, 5, 1], [0, 9, 0, 0], [2, 0, 178, 0], [2, 1, 0, 7]]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = [[acc_acc, acc_good, acc_unacc, acc_vgood],\n",
    "                   [good_acc, good_good, good_unacc, good_vgood],\n",
    "                   [unacc_acc, unacc_good, unacc_unacc, unacc_vgood],\n",
    "                   [vgood_acc, vgood_good, vgood_unacc, vgood_vgood]]\n",
    "print(confusion_matrix)\n",
    "print(type(confusion_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a01a284-7401-48c1-a36b-adba5c833043",
   "metadata": {},
   "source": [
    "__Manually Calculating the Test Set's Accuracy from the Manually Built Confusion Matrix__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2b8e1d65-bdf8-4e96-b520-a44c16f16163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95\n"
     ]
    }
   ],
   "source": [
    "print((acc_acc + good_good + unacc_unacc + vgood_vgood) / sum(sum(row) for row in confusion_matrix))\n",
    "\n",
    "# print((acc_acc + good_good + unacc_unacc + vgood_vgood) / (acc_acc + acc_good + acc_unacc + acc_vgood + good_acc + good_good + good_unacc + good_vgood + unacc_acc + unacc_good + unacc_unacc + unacc_vgood + vgood_acc + vgood_good + vgood_unacc + vgood_vgood))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a6f41e-47b1-4fe3-a4e3-6f56bfb3a2e6",
   "metadata": {},
   "source": [
    "__Accuracy of the Single Decision Tree on the Test Set__ `using the Sklearn Implementation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6f3e78db-8bbc-4120-8164-cdce03598e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# y_test_pred = single_decision_tree_classifier.predict(X_test)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0b8dec-7736-447f-83bb-26ad89ff0fb9",
   "metadata": {},
   "source": [
    "__Manually Calculating the Test Set's Precision & Recall from the Manually Built Confusion Matrix__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "be1b2fb0-48ba-400f-9bb9-5960137d7957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of acc: 0.9298245614035088\n",
      "Precision of good: 0.75\n",
      "Precision of unacc: 0.9726775956284153\n",
      "Precision of vgood: 0.875\n",
      "---------------------------------------\n",
      "Average Precision: 0.881875539257981\n",
      "---------------------------------------\n",
      "Recall of acc: 0.8688524590163934\n",
      "Recall of good: 1.0\n",
      "Recall of unacc: 0.9888888888888889\n",
      "Recall of vgood: 0.7\n",
      "---------------------------------------\n",
      "Average recall: 0.8894353369763206\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Average F1 Score: 0.8856393058440672\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Precision of acc\n",
    "# print(acc_acc / (acc_acc + good_acc + unacc_acc + vgood_acc))\n",
    "Precision_of_acc = acc_acc / (acc_acc + good_acc + unacc_acc + vgood_acc)\n",
    "print(f\"Precision of acc: {Precision_of_acc}\")\n",
    "\n",
    "# Precision of good\n",
    "# print(good_good / (acc_good + good_good + unacc_good + vgood_good))\n",
    "Precision_of_good = good_good / (acc_good + good_good + unacc_good + vgood_good)\n",
    "print(f\"Precision of good: {Precision_of_good}\")\n",
    "\n",
    "# Precision of unacc\n",
    "# print(unacc_unacc / (acc_unacc + good_unacc + unacc_unacc + vgood_unacc))\n",
    "Precision_of_unacc = unacc_unacc / (acc_unacc + good_unacc + unacc_unacc + vgood_unacc)\n",
    "print(f\"Precision of unacc: {Precision_of_unacc}\")\n",
    "\n",
    "# Precision of vgood\n",
    "# print(vgood_vgood / (acc_vgood + good_vgood + unacc_vgood + vgood_vgood))\n",
    "Precision_of_vgood = vgood_vgood / (acc_vgood + good_vgood + unacc_vgood + vgood_vgood)\n",
    "print(f\"Precision of vgood: {Precision_of_vgood}\")\n",
    "\n",
    "# Average precision\n",
    "average_precision = (Precision_of_acc + Precision_of_good + Precision_of_unacc + Precision_of_vgood) / 4.0\n",
    "print(\"---------------------------------------\")\n",
    "print(f\"Average Precision: {average_precision}\")\n",
    "print(\"---------------------------------------\")\n",
    "\n",
    "# Recall of acc\n",
    "Recall_of_acc = acc_acc / (acc_acc + acc_good + acc_unacc + acc_vgood)\n",
    "print(f\"Recall of acc: {Recall_of_acc}\")\n",
    "\n",
    "# Recall of good\n",
    "Recall_of_good = good_good / (good_acc + good_good + good_unacc + good_vgood)\n",
    "print(f\"Recall of good: {Recall_of_good}\")\n",
    "\n",
    "# Recall of unacc\n",
    "Recall_of_unacc = unacc_unacc / (unacc_acc + unacc_good + unacc_unacc + unacc_vgood)\n",
    "print(f\"Recall of unacc: {Recall_of_unacc}\")\n",
    "\n",
    "# Recall of vgood\n",
    "Recall_of_vgood = vgood_vgood / (vgood_acc + vgood_good + vgood_unacc + vgood_vgood)\n",
    "print(f\"Recall of vgood: {Recall_of_vgood}\")\n",
    "\n",
    "# Average recall\n",
    "average_recall = (Recall_of_acc + Recall_of_good + Recall_of_unacc + Recall_of_vgood) / 4.0\n",
    "print(\"---------------------------------------\")\n",
    "print(f\"Average recall: {average_recall}\")\n",
    "print(\"---------------------------------------\")\n",
    "\n",
    "# Average F1 Score\n",
    "average_f1_score = 2 * ((average_precision * average_recall) / (average_precision + average_recall))\n",
    "print(\"---------------------------------------\")\n",
    "print(f\"Average F1 Score: {average_f1_score}\")\n",
    "print(\"---------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08d9259-f108-4137-b3ee-ea6086839150",
   "metadata": {},
   "source": [
    "__Confusion Matrix, Precision, Recall, F1 Score on the Test Set__ `using the Sklearn Implementation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8a0f8a1b-ae5d-4557-b4d1-610f3ae5c4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix using sklearn:\n",
      "[[ 53   2   5   1]\n",
      " [  0   9   0   0]\n",
      " [  2   0 178   0]\n",
      " [  2   1   0   7]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90        61\n",
      "           1       0.75      1.00      0.86         9\n",
      "           2       0.97      0.99      0.98       180\n",
      "           3       0.88      0.70      0.78        10\n",
      "\n",
      "    accuracy                           0.95       260\n",
      "   macro avg       0.88      0.89      0.88       260\n",
      "weighted avg       0.95      0.95      0.95       260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "y_test_labels = np.argmax(y_test.values, axis=1)\n",
    "y_test_pred_labels = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test_labels, y_test_pred_labels)\n",
    "\n",
    "print(\"Confusion Matrix using sklearn:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_labels, y_test_pred_labels, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c958b2c8-94e7-4c2d-b097-d6104432f5cf",
   "metadata": {},
   "source": [
    "__XGBOOST__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d9e92659-0004-43b1-8302-99e21cc81047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Precision: [0.98113208 0.7        1.         0.84615385]\n",
      "Validation Recall: [0.9122807  0.7        1.         0.78571429]\n",
      "Validation F1-score: [0.94545455 0.7        1.         0.81481481]\n",
      "Validation Support: [ 57  10 178  14]\n",
      "Test Accuracy: 0.9461538461538461\n",
      "Test Precision: [0.98113208 0.66666667 1.         1.        ]\n",
      "Test Recall: [0.85245902 0.88888889 1.         0.7       ]\n",
      "Test F1-score: [0.9122807  0.76190476 1.         0.82352941]\n",
      "Test Support: [ 61   9 180  10]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "multilabel-indicator is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 41\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Support:\u001b[39m\u001b[38;5;124m\"\u001b[39m, support)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Confusion Matrix for test set\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(y_test, y_pred_test)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfusion Matrix:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, cm)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:321\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    319\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 321\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    324\u001b[0m     labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "\u001b[1;31mValueError\u001b[0m: multilabel-indicator is not supported"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support, precision_recall_curve, accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create an XGBoost Classifier\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred_val = xgb_model.predict(X_val)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "precision, recall, f1, support = precision_recall_fscore_support(y_val, y_pred_val, average=None)\n",
    "print(\"Validation Precision:\", precision)\n",
    "print(\"Validation Recall:\", recall)\n",
    "print(\"Validation F1-score:\", f1)\n",
    "print(\"Validation Support:\", support)\n",
    "\n",
    "# # Precision-Recall Curve for validation set\n",
    "# precision_curve, recall_curve, thresholds = precision_recall_curve(y_val, xgb_model.predict_proba(X_val)[:, 1])\n",
    "# plt.plot(recall_curve, precision_curve)\n",
    "# plt.xlabel('Recall')\n",
    "# plt.ylabel('Precision')\n",
    "# plt.title('Precision-Recall Curve (Validation)')\n",
    "# plt.show()\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred_test = xgb_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred_test)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "precision, recall, f1, support = precision_recall_fscore_support(y_test, y_pred_test, average=None)\n",
    "print(\"Test Precision:\", precision)\n",
    "print(\"Test Recall:\", recall)\n",
    "print(\"Test F1-score:\", f1)\n",
    "print(\"Test Support:\", support)\n",
    "\n",
    "# Confusion Matrix for test set\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# # Precision-Recall Curve for test set\n",
    "# precision_curve, recall_curve, thresholds = precision_recall_curve(y_test, xgb_model.predict_proba(X_test)[:, 1])\n",
    "# plt.plot(recall_curve, precision_curve)\n",
    "# plt.xlabel('Recall')\n",
    "# plt.ylabel('Precision')\n",
    "# plt.title('Precision-Recall Curve (Test)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3924c333-4df2-4636-9308-0abd318410dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Initialize the XGBoost model\n",
    "xgb_model = XGBClassifier(colsample_bytree = 1, n_estimators=200, learning_rate=0.1, max_depth=11, random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "f1_xgb = f1_score(y_test, y_pred_xgb, average='weighted')\n",
    "precision_xgb = precision_score(y_test, y_pred_xgb, average='weighted')\n",
    "recall_xgb = recall_score(y_test, y_pred_xgb, average='weighted')\n",
    "\n",
    "# Display the evaluation metrics\n",
    "print(\"XGBoost Model Performance:\")\n",
    "print(f\"F1 Score: {f1_xgb}\")\n",
    "print(f\"Precision: {precision_xgb}\")\n",
    "print(f\"Recall: {recall_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e54cff6-c292-40f0-897b-2b1c133cfe56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
